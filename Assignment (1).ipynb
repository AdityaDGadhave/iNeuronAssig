{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "\n",
        "def convert_dict_to_list(input_dict):\n",
        "\n",
        "  output_dict = {}\n",
        "  def func(current_dict, path):\n",
        "    for key, value in current_dict.items():\n",
        "      new_path = path + [key]\n",
        "      if isinstance(value, str):\n",
        "        output_dict[new_path[-1]] = value\n",
        "      else:\n",
        "        output_dict.setdefault(new_path[-1], []).append(key)\n",
        "        func(value, new_path)\n",
        "  func(input_dict, [])\n",
        "  return output_dict\n",
        "\n",
        "# Example usage\n",
        "input_dict = {\"abc\":{\"def\":{\"ghi\":{\"jkl\":{\"mno\":{\"pqr\":{\"stu\":{\"vwx\":{\"yz\":\"you are finally here !!!\"}}}}}}}}}\n",
        "output_dict = convert_dict_to_list(input_dict)\n",
        "print(output_dict)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxvrdxjZjcEW",
        "outputId": "7df54ab3-d12d-4681-932d-50fbe508ec30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'abc': ['abc'], 'def': ['def'], 'ghi': ['ghi'], 'jkl': ['jkl'], 'mno': ['mno'], 'pqr': ['pqr'], 'stu': ['stu'], 'vwx': ['vwx'], 'yz': 'you are finally here !!!'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2)\n",
        "\n",
        "def max_min_distance(stalls, k):\n",
        "    stalls.sort()\n",
        "    n = len(stalls)\n",
        "    max_min_distance = float('inf')\n",
        "    left = 0\n",
        "    right = k - 1\n",
        "    while right < n:\n",
        "        max_min_distance = min(max_min_distance, stalls[right] - stalls[left])\n",
        "        left += 1\n",
        "        right += 1\n",
        "    return max_min_distance\n",
        "\n",
        "array = [1, 2, 4, 8, 9]\n",
        "k = 3\n",
        "print('here we go and answer is :-> ',max_min_distance(array, k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvcjx-u5kPqn",
        "outputId": "3f2d792c-f995-4cc7-dc5a-3d1466f55d20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here we go and answer is :->  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "\n",
        "\n",
        "def designer_door_mat(n, m):\n",
        "\n",
        "  if n % 2 == 0 or m % 3 != 0:\n",
        "    raise ValueError(\"Invalid input: N must be odd and M must be a multiple of 3.\")\n",
        "\n",
        "  center_row = n // 2    #<------floor division\n",
        "  center_col = m // 2\n",
        "\n",
        "\n",
        "  for i in range(center_row):\n",
        "    num_dots = (m - 3 * (i + 1)) // 2\n",
        "    pattern = f\"{'-'*num_dots}.|.{'-'*num_dots}\"\n",
        "    print(pattern.center(m, '-'))\n",
        "\n",
        "\n",
        "  print('WELCOME'.center(m, '-'))\n",
        "\n",
        "\n",
        "  for i in range(center_row - 1, -1, -1):\n",
        "    num_dots = (m - 3 * (i + 1)) // 2\n",
        "    pattern = f\"{'-'*num_dots}.|.{'-'*num_dots}\"\n",
        "    print(pattern.center(m, '-'))\n",
        "\n",
        "n = 7\n",
        "m = 21\n",
        "designer_door_mat(n, m)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRilau-5pABp",
        "outputId": "3486dfca-4507-4894-d231-d6649fe158a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.|.---------\n",
            "---------.|.---------\n",
            "---------.|.---------\n",
            "-------WELCOME-------\n",
            "---------.|.---------\n",
            "---------.|.---------\n",
            "---------.|.---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4)\n",
        "\n",
        "\n",
        "def fourSum(nums, target):\n",
        "    nums.sort()\n",
        "    n = len(nums)\n",
        "    quadruplets = []\n",
        "\n",
        "    for i in range(n - 3):\n",
        "        if i > 0 and nums[i] == nums[i - 1]:\n",
        "            continue\n",
        "\n",
        "        for j in range(i + 1, n - 2):\n",
        "            if j > i + 1 and nums[j] == nums[j - 1]:\n",
        "                continue\n",
        "\n",
        "            left = j + 1\n",
        "            right = n - 1\n",
        "\n",
        "            while left < right:\n",
        "                total = nums[i] + nums[j] + nums[left] + nums[right]\n",
        "\n",
        "                if total == target:\n",
        "                    quadruplets.append([nums[i], nums[j], nums[left], nums[right]])\n",
        "                    left += 1\n",
        "                    right -= 1\n",
        "\n",
        "                    while left < right and nums[left] == nums[left - 1]:\n",
        "                        left += 1\n",
        "                    while left < right and nums[right] == nums[right + 1]:\n",
        "                        right -= 1\n",
        "\n",
        "                elif total < target:\n",
        "                    left += 1\n",
        "                else:\n",
        "                    right -= 1\n",
        "\n",
        "    return quadruplets\n",
        "nums = [1, 0, -1, 0, -2, 2]\n",
        "target = 0\n",
        "result = fourSum(nums, target)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khtmcaHwq_pB",
        "outputId": "8be488d5-22f8-4ff3-de21-7aaca51b35de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2, -1, 1, 2], [-2, 0, 0, 2], [-1, 0, 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL\n"
      ],
      "metadata": {
        "id": "2BA71Ques5GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SELECT * FROM runners WHERE id NOT IN (SELECT winner_id FROM races);\n",
        "\n",
        "Expalnaton:->   The inner query (SELECT winner_id FROM races) retrieves all winner_id values from the races table.\n",
        "\n",
        "The outer query SELECT * FROM runners WHERE id NOT IN (...) selects all rows from the runners table where the id is not present in the winner_id column of the races table.\n",
        "\n",
        "if there are NULL values in the winner_id column of the races table, the query may not work as expected because NOT IN doesn't behave as expected when dealing with NULL values.\n",
        "\n",
        " To handle NULL values correctly, you can rewrite the query using a subquery with NOT EXISTS\n",
        "\n",
        "\n",
        "\n",
        " SELECT * FROM runners\n",
        "WHERE NOT EXISTS (SELECT 1 FROM races WHERE races.winner_id = runners.id);\n",
        "\n",
        "\n",
        "with this query we can handle Null error\n",
        "\n",
        "This query will select all rows from the runners table where there is no corresponding id in the winner_id column of the races table, including rows where winner_id is NULL."
      ],
      "metadata": {
        "id": "S42rHlEetyZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2)\n",
        "\n",
        "\n",
        "SELECT a.id\n",
        "FROM test_a a\n",
        "LEFT JOIN test_b b ON a.id = b.id\n",
        "WHERE b.id IS NULL;\n"
      ],
      "metadata": {
        "id": "EUl0YMNTushY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3)\n",
        "\n",
        "SELECT u.username, td.training_id, td.training_date\n",
        "FROM users u\n",
        "JOIN training_details td ON u.user_id = td.user_id\n",
        "GROUP BY u.username, td.training_id, td.training_date\n",
        "HAVING COUNT(*) > 1\n",
        "ORDER BY td.training_date DESC;\n"
      ],
      "metadata": {
        "id": "3dAfS6v7vpxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4)\n",
        "\n",
        "\n",
        "SELECT Manager_Id,\n",
        "       Manager,\n",
        "       AVG(Salary) AS Average_Salary_Under_Manager\n",
        "FROM (\n",
        "    SELECT e1.Manager_Id,\n",
        "           e1.Emp_name AS Manager,\n",
        "           e2.Salary\n",
        "    FROM Employees e1\n",
        "    JOIN Employees e2 ON e1.Emp_id = e2.Manager_Id\n",
        ") AS Subquery\n",
        "GROUP BY Manager_Id, Manager\n",
        "ORDER BY Manager_Id;\n"
      ],
      "metadata": {
        "id": "k5__ZJli0ZZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Statistics\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g2JdZ0zP02Po"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1)\n",
        "\n",
        "What is the meaning of six sigma in statistics?  Give proper example\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Six Sigma is a methodology used in statistics and business to improve process quality by minimizing defects and variation. It's based on the concept that any process can be statistically measured and improved. Here's a breakdown of its meaning and an example:\n",
        "\n",
        "Meaning:\n",
        "\n",
        "Six Sigma refers to a statistical measure of how far a process deviates from perfection. A process is considered \"Six Sigma\" if its quality is within 6 standard deviations of the mean value.\n",
        "\n",
        "Standard deviation is a statistical measure that indicates how spread out the data points are from the average value. A smaller standard deviation means the data points are closer to the mean, indicating less variation.\n",
        "\n",
        "In simpler terms, Six Sigma aims to achieve a process where only 3.4 defects occur per million opportunities. This incredibly low defect rate signifies a highly reliable and efficient process.\n",
        "Example:\n",
        "\n",
        "Imagine a manufacturing company that produces bottles. They want to ensure the bottles are filled to the correct capacity. Here's how Six Sigma could be applied:\n",
        "\n",
        "Measure current performance: The company measures the actual fill volume of a large sample of bottles.\n",
        "\n",
        "Analyze data: They analyze the data to find the average fill volume and standard deviation.\n",
        "\n",
        "Define acceptable limits: They define an acceptable fill range (e.g., within +/- 0.5 ml of the target volume).\n",
        "\n",
        "Identify defects: Any bottle outside the acceptable range is considered a defect.\n",
        "\n",
        "Improve the process: Based on the data, the company identifies and implements improvements to minimize variations in the filling process.\n",
        "\n",
        "This could involve calibrating machines, improving material handling, or implementing stricter quality control procedures.\n",
        "\n",
        "Monitor and control: The company continues to monitor the process and adjust it as needed to maintain a low defect rate.\n",
        "\n",
        "By following these steps and achieving Six Sigma quality, the bottle filling process would become highly reliable, with a very low probability of producing bottles outside the acceptable fill range. This reduces waste, improves customer satisfaction, and potentially saves the company money.\n",
        "\n",
        "Six Sigma goes beyond this simple example and can be applied to various processes in different industries"
      ],
      "metadata": {
        "id": "NQfErM1l1yXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SlTwnCpS3ux2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2)\n",
        "\n",
        "What type of data does not have a log-normal distribution or a Gaussian distribution?  Give proper example\n",
        "\n",
        "\n",
        "There are several types of data that may not follow a log-normal or Gaussian (normal) distribution. Here are a few examples:\n",
        "\n",
        "1. Discrete Data with Limited Range:\n",
        "\n",
        "Example: Number of siblings a person has (0, 1, 2, 3, etc.). This data is discrete (whole numbers) and has a limited range. A normal or log-normal distribution wouldn't be suitable because it can theoretically extend infinitely on both sides. We might use a Poisson distribution or a binomial distribution for such data, depending on the context.\n",
        "2. Data with a Strong Skew:\n",
        "\n",
        "Example: Income distribution in a country. Incomes are often skewed to the right, with a few very high earners and many people with lower incomes. A normal distribution, which is symmetrical, wouldn't accurately represent this. We might use a Pareto distribution or a log-normal distribution (in some cases) for skewed income data.\n",
        "3. Data with Bounded Limits:\n",
        "\n",
        "Example: Exam scores with a fixed grading scale (0-100%). Both normal and log-normal distributions can extend infinitely on one or both sides, which wouldn't be appropriate for scores limited by the grading scale. We might use a uniform distribution (for scores spread evenly across the range) or other distributions depending on the specific grading system.\n",
        "4. Categorical Data:\n",
        "\n",
        "Example: Blood type (A, B, AB, O). Categorical data doesn't represent numerical values but rather distinct categories. Neither normal nor log-normal distributions are applicable here.\n",
        "5. Spiky or Highly Variable Data:\n",
        "\n",
        "Example: Daily website traffic. Website traffic can have sudden spikes and dips, violating the smoothness assumption of normal and log-normal distributions. We might use more complex models or statistical methods to analyze such data."
      ],
      "metadata": {
        "id": "E_8JvtoS1_W-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wK4mSnKi3Pcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3)\n",
        "\n",
        "\n",
        "What is the meaning of the five-number summary in Statistics? Give proper example\n",
        "\n",
        "\n",
        "The five-number summary is a descriptive statistics technique used to summarize the distribution of a dataset. It provides a concise summary of the central tendency, variability, and shape of the data. The five numbers typically include the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum of the dataset.\n",
        "\n",
        "Here's what each of the five numbers represents:\n",
        "\n",
        "Minimum: The smallest value in the dataset.\n",
        "First Quartile (Q1): The value below which 25% of the data falls. It is also the median of the lower half of the dataset.\n",
        "Median (Q2): The middle value of the dataset when it is sorted in ascending order. It represents the value below which 50% of the data falls.\n",
        "Third Quartile (Q3): The value below which 75% of the data falls. It is also the median of the upper half of the dataset.\n",
        "Maximum: The largest value in the dataset.\n",
        "The five-number summary can be represented visually using a box plot, where the minimum, Q1, median, Q3, and maximum are plotted on a scale. This visualization helps to identify the spread and skewness of the data, as well as detect outliers."
      ],
      "metadata": {
        "id": "8Q4Aa0vG3cHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BTLyJOX13dXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " It indicates the strength and direction of the linear relationship between the variables. The correlation coefficient, often denoted by \"r,\" ranges from -1 to 1, where:\n",
        "\n",
        "1 indicates a perfect positive linear relationship (as one variable increases, the other variable increases).\n",
        "-1 indicates a perfect negative linear relationship (as one variable increases, the other variable decreases).\n",
        "0 indicates no linear relationship between the variables.\n",
        "Correlation is a dimensionless quantity, meaning it does not have any units. It only measures the strength and direction of the linear relationship, not the slope of the relationship.\n",
        "\n",
        "Here's an example of correlation with a dataset:\n",
        "\n",
        "Suppose we have a dataset consisting of two variables: the number of hours studied (X) and the exam score achieved (Y) by a group of students."
      ],
      "metadata": {
        "id": "7BFyaaGl4GKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Hours_Studied= [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "Exam_Score=  [60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Dataset\n",
        "hours_studied = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "exam_score = np.array([60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
        "\n",
        "# Calculate correlation coefficient\n",
        "correlation_coefficient = np.corrcoef(hours_studied, exam_score)[0, 1]\n",
        "print(\"Correlation coefficient:\", correlation_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMosvakw4Xh4",
        "outputId": "b612daa5-2657-453b-c97b-00d18fb50271"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(hours_studied, exam_score)\n",
        "plt.title(\"Scatter Plot of Hours Studied vs Exam Score\")\n",
        "plt.xlabel(\"Hours Studied\")\n",
        "plt.ylabel(\"Exam Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7CcQS9bF4jPv",
        "outputId": "cbec50bb-36e4-423a-d7b1-5c025b36a224"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning"
      ],
      "metadata": {
        "id": "t5V_bWkh7Dfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Imagine you have a dataset where you have different Instagram features like u sername , Caption , Hashtag , Followers ,\n",
        "Time_Since_posted , and likes , now your task is to predict the number of likes and Time Since posted and the rest of the features are your input\n",
        " features. Now you have to build a model which can predict the number of likes and Time Since posted.'''\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "data = pd.read_csv(r\"https://www.kaggle.com/datasets/rxsraghavagrawal/instagram-reach\")\n",
        "\n",
        "# Drop unnecessary columns like 'username', 'caption', and 'hashtag'\n",
        "data.drop(['Username', 'Caption', 'Hashtags'], axis=1, inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna({'Followers': data['Followers'].median()}, inplace=True)\n",
        "\n",
        "# Split the data into input features (X) and target variables (y_likes, y_time_since_posted)\n",
        "X = data.drop(['Likes', 'Time_since_posted'], axis=1)\n",
        "y_likes = data['Likes']\n",
        "y_time_since_posted = data['Time_since_posted']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_likes_train, y_likes_test, y_time_train, y_time_test = train_test_split(X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Feature Engineering (No additional feature engineering for now)\n",
        "\n",
        "# Step 3: Model Selection\n",
        "\n",
        "numeric_features = ['Followers']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_features = ['Location']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define models\n",
        "model_likes = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_time_since_posted = LinearRegression()\n",
        "\n",
        "# Step 4: Model Training\n",
        "\n",
        "pipeline_likes = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                 ('model', model_likes)])\n",
        "pipeline_time_since_posted = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                             ('model', model_time_since_posted)])\n",
        "\n",
        "# Fit the models\n",
        "pipeline_likes.fit(X_train, y_likes_train)\n",
        "pipeline_time_since_posted.fit(X_train, y_time_train)\n",
        "\n",
        "# Step 5: Model Evaluation\n",
        "\n",
        "y_likes_pred = pipeline_likes.predict(X_test)\n",
        "y_time_pred = pipeline_time_since_posted.predict(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "likes_mse = mean_squared_error(y_likes_test, y_likes_pred)\n",
        "likes_mae = mean_absolute_error(y_likes_test, y_likes_pred)\n",
        "time_mae = mean_absolute_error(y_time_test, y_time_pred)\n",
        "\n",
        "print(\"Likes Prediction Metrics:\")\n",
        "print(\"Mean Squared Error:\", likes_mse)\n",
        "print(\"Mean Absolute Error:\", likes_mae)\n",
        "print(\"\\nTime Since Posted Prediction Metrics:\")\n",
        "print(\"Mean Absolute Error:\", time_mae)\n",
        "\n"
      ],
      "metadata": {
        "id": "yw6BfG0v7MdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KfE9dCuz828t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Check the data types and missing values\n",
        "print(data.info())\n",
        "\n",
        "# Summary statistics\n",
        "print(data.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Check unique values in categorical features\n",
        "print(data['area_type'].value_counts())\n",
        "print(data['availability'].value_counts())\n",
        "print(data['location'].value_counts())\n",
        "print(data['size'].value_counts())\n",
        "print(data['society'].value_counts())\n",
        "print(data['total_sqft'].value_counts())\n",
        "print(data['bath'].value_counts())\n",
        "print(data['balcony'].value_counts())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = data.drop(['price'], axis=1)\n",
        "y = data['price']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing steps for numeric and categorical features\n",
        "numeric_features = ['bath', 'balcony', 'total_sqft']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_features = ['area_type', 'availability', 'location', 'size', 'society']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define the SVM regressor\n",
        "svm_regressor = SVR()\n",
        "\n",
        "# Create a pipeline with preprocessing and SVM regressor\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('regressor', svm_regressor)])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "train_score = model.score(X_train, y_train)\n",
        "test_score = model.score(X_test, y_test)\n",
        "print(\"Training R^2 score:\", train_score)\n",
        "print(\"Testing R^2 score:\", test_score)\n"
      ],
      "metadata": {
        "id": "xtVbrZWa9TAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4)\n",
        "'''Train and fine tune a decision tree using the wine dataset by following the following steps:-\n",
        "\n",
        "  1. Use load_wine() to generate wine dataset\n",
        "  2. Split the dataset into train and test  dataset\n",
        "  3. Use random search CV to hyperparameter tune the Decision Tree\n",
        "  4. Try to achieve an accuracy of at least 85%\n",
        "\n",
        "\n",
        "Grow a random forest using the following steps:-\n",
        "\n",
        "  1. Continuing the previous question, create 10 subsets of the training dataset. You can use the ShuffleSplit                class for it.\n",
        "  2. Train 1 decision tree on each subset, using the best hyperparameter values found in the previous question.\n",
        "  3. Evaluate all the trees on the test dataset. Are they performing better than the tree created in the previous question?'''\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, ShuffleSplit\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Step 1: Load the wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Step 2: Split the dataset into train and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Hyperparameter tuning using RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'max_depth': randint(1, 20),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 20),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "random_search = RandomizedSearchCV(dt, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found by RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# Step 4: Evaluate the decision tree model\n",
        "best_dt_model = random_search.best_estimator_\n",
        "accuracy_dt = best_dt_model.score(X_test, y_test)\n",
        "print(\"Accuracy of the Decision Tree model:\", accuracy_dt)\n",
        "\n",
        "# Step 5: Grow a random forest\n",
        "# Create 10 subsets of the training dataset\n",
        "rs = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
        "forest = []\n",
        "for train_index, _ in rs.split(X_train):\n",
        "    subset_X_train, subset_y_train = X_train[train_index], y_train[train_index]\n",
        "\n",
        "    # Train decision tree on each subset using best hyperparameters\n",
        "    dt = DecisionTreeClassifier(**random_search.best_params_)\n",
        "    dt.fit(subset_X_train, subset_y_train)\n",
        "    forest.append(dt)\n",
        "\n",
        "# Evaluate all trees on the test dataset\n",
        "accuracy_forest = sum(dt.score(X_test, y_test) for dt in forest) / len(forest)\n",
        "print(\"Average accuracy of the Random Forest:\", accuracy_forest)\n"
      ],
      "metadata": {
        "id": "_gkjPSJl_MH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning"
      ],
      "metadata": {
        "id": "yJ2y5lQ9AhFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1\n",
        "\n",
        "\n",
        "\n",
        "Problem Definition and Data Collection:\n",
        "\n",
        "Clearly define the problem you want to solve and determine whether DL is the appropriate approach.\n",
        "Gather relevant data for training and validation. Ensure the data is labeled (if applicable) and sufficiently large and diverse to represent the problem space.\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "Clean the data by handling missing values, outliers, and inconsistencies.\n",
        "\n",
        "Normalize or standardize the data to ensure features are on a similar scale.\n",
        "\n",
        "Split the data into training, validation, and test sets.\n",
        "\n",
        "Model Selection and Architecture Design:\n",
        "\n",
        "Choose a DL architecture (e.g., convolutional neural networks for image data, recurrent neural networks for sequential data) based on the problem requirements and characteristics of the data.\n",
        "\n",
        "Design the architecture, including the number of layers, types of layers,\n",
        "\n",
        "activation functions, regularization techniques, and optimization algorithms.\n",
        "\n",
        "\n",
        "Model Training:\n",
        "\n",
        "Train the DL model on the training data using backpropagation and gradient descent.\n",
        "\n",
        "Monitor training progress by evaluating performance metrics on the validation set and adjusting hyperparameters as needed.\n",
        "\n",
        "Prevent overfitting by applying regularization techniques (e.g., dropout, L2 regularization) and early stopping.\n",
        "\n",
        "\n",
        "Model Evaluation:\n",
        "\n",
        "Evaluate the trained model on the test set to assess its generalization performance.\n",
        "\n",
        "Measure performance metrics such as accuracy, precision, recall, F1-score, and ROC-AUC depending on the problem type (classification, regression, etc.).\n",
        "\n",
        "\n",
        "Deployment and Integration:\n",
        "\n",
        "Deploy the trained model into a production environment, which may involve packaging the model as a service or embedding it within an application.\n",
        "\n",
        "Integrate the model with existing systems or workflows, ensuring compatibility and seamless operation.\n",
        "\n",
        "Monitor the model's performance in real-world scenarios and update it periodically as needed.\n",
        "\n",
        "\n",
        "Scalability and Efficiency:\n",
        "\n",
        "Ensure the DL solution can handle large volumes of data and scale efficiently to meet growing demands.\n",
        "\n",
        "Optimize the model's performance and resource utilization to minimize inference time and computational costs.\n",
        "\n",
        "\n",
        "Continuous Improvement and Maintenance:\n",
        "\n",
        "Monitor the model's performance over time and collect feedback from users or stakeholders.\n",
        "\n",
        "Continuously update and improve the model based on new data, changing requirements, and advancements in DL techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qtzd5oFaA9BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CsYY3CUqB31S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "b)What is the use of Activation function in Artificial Neural Networks? What would be the problem if we don't use it in ANN networks.\n",
        "\n",
        "\n",
        "Activation functions play a crucial role in artificial neural networks (ANNs) by introducing non-linearity into the network. They allow neural networks to learn and model complex patterns and relationships within the data. The primary purposes and uses of activation functions in ANNs are as follows:\n",
        "\n",
        "Introducing non-linearity:\n",
        "\n",
        " Activation functions introduce non-linear transformations to the output of neurons in each layer of the neural network. Without non-linear activation functions, the entire neural network would behave like a linear regression model, making it limited in its capacity to learn complex patterns and relationships in the data.\n",
        "\n",
        "Enabling complex mappings:\n",
        "\n",
        "The non-linear properties introduced by activation functions enable ANNs to approximate complex functions, including those with non-linearities and irregularities. This ability is essential for capturing the intricate relationships present in real-world data, such as images, text, and time series.\n",
        "\n",
        "Supporting gradient-based optimization:\n",
        "\n",
        " Activation functions ensure that the network remains differentiable, allowing for the use of gradient-based optimization algorithms (e.g., backpropagation) to update the network's parameters during training. This enables efficient learning of the model parameters through the iterative adjustment of weights and biases.\n",
        "\n",
        "Controlling neuron activation:\n",
        "\n",
        "Activation functions control the magnitude and range of neuron activations, ensuring that the output of each neuron falls within a desired range. This can help stabilize the learning process and prevent issues such as exploding or vanishing gradients, which can hinder training convergence in deep networks.\n",
        "\n",
        "If activation functions were not used in ANNs, the networks would be limited to linear transformations of the input data. As a result, the network would not be able to learn and represent complex patterns and relationships in the data, severely limiting its modeling capabilities.\n",
        "\n",
        " The lack of non-linearity would render the network incapable of approximating non-linear functions effectively, making it unsuitable for tasks requiring complex pattern recognition, such as image classification, natural language processing, and speech recognition.\n",
        "\n",
        "  Additionally, without activation functions, gradient-based optimization algorithms would not be applicable, preventing efficient training of the network parameters. Overall, activation functions are essential components of ANNs, enabling them to perform complex learning tasks and achieve high levels of performance in various real-world applications."
      ],
      "metadata": {
        "id": "ek2HyndrB4oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MvEOlrvbBAhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2) Train a Pure ANN with less than 10000 trainable parameters using the MNIST Dataset\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Step 3: Design the ANN architecture\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(28 * 28,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n"
      ],
      "metadata": {
        "id": "MeKPSeasCgp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3)Perform Regression Task using ANN\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Step 1: Load the Boston Housing dataset\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Design the ANN architecture\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer with one neuron for regression\n",
        "])\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 5: Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n"
      ],
      "metadata": {
        "id": "RSbUyzp1C2OK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}